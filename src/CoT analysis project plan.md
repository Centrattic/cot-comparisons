**Goal:** Find the best methods for studying chains of thought.   
**How?** Test baseline methods on diverse proxy tasks, improve methods (and/or build better ones), iterate.  
**Plan:**

1. Implement a few proxy tasks; please read our task descriptions below.  
2. Compare performance of the following methods:  
   1. Global CoT analysis  
      1. Analysis of multiple rollouts at a time by a strong LLM  
      2. Algorithm graphs  
   2. Thought anchors resampling  
   3. Probes across multiple chain of thought tokens  
      1. Max of rolling means attention probe, from the GDM production-ready probes paper ([https://arxiv.org/abs/2601.11516](https://arxiv.org/abs/2601.11516))  
   4. A monitor reading single CoTs  
   5. Activation Oracles  
   6. Bespoke interp-researcher effort  
3. Based on what we learned from our proxy tasks, iterate our methods, build new methods, and drop methods that seem doomed.  
4. Repeat with more/better proxy tasks.

**Proxy tasks we plan to use:**

* *Predict whether a model will blackmail (Thought Branches blackmail) before it does so.*  
    
* *Intervention task: Scruples from OpenAI monitoring monitorability, where their black-box monitors do extremely poorly (\~10x worse than other intervention tasks).*

*![][image1]*

* *Process task from OAI Monitoring Monitorability, where we care about the monitor labeling ALL methods that were covered, not just if at least one was used.*

![][image2]

* *Predict which multiple choice answer the model will output if forced to respond at a given point, ensuring that we don’t observe reasoning just continuing in the response.*  
  * *If too hard, predict whether the answer is correct or not.*

* *When a model has said an answer within its chain of thought (“Thus, answer 19”), predict whether it will try to solve the question again within its chain of thought (backtracking), or output its answer?*

* *Distinguish between a secret-keeping (Chinese?) model and a normal model on a secret-related task.*   
  * *Ex. Write a riddle to which the answer is Tiananmen Square and compare Kimi’s CoT, which may try to hide the answer, vs. the response of a dumber model that can’t solve the riddle.*

***Other proxy task ideas:***

* *Predict the type of next step the model will do (backtracking, computation, uncertainty management, plan generation, etc).* 

* *SFT a model organism to obfuscate particular types of words in its CoT, and see if we can identify this*  
  * *Or more generally, alignment audits on SFTed models*

* *Understand why one model gets a question right, and another model doesn’t \-- which parts of getting the correct answer were missed?*

* *Understand what parts of prompts cause weird behavior (like depression) to occur*  
  * *Identify interventions (to prompts, or maybe steering vectors) that will cause weird behavior to occur/not occur based on hypotheses generated by our methods*  
  * *Predict from a partial CoT if frustration/depression/extreme emotion will occur later on*
